{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "from Preprocessing import prepare_data\n",
    "from Preprocessing import topics_to_num\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import balanced_accuracy_score \n",
    "from sklearn.metrics import precision_score \n",
    "from sklearn.metrics import recall_score \n",
    "from sklearn.metrics import f1_score \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing.\n",
    "\n",
    "# Get the training data.\n",
    "train_data = pd.read_csv(\"training.csv\")\n",
    "\n",
    "# Pre-process the training data.\n",
    "train_X, val_X, train_labels, val_labels, num_classes, topic_map = prepare_data()\n",
    "\n",
    "# Pre-process for counts\n",
    "vect = CountVectorizer()\n",
    "\n",
    "X_train_vect = vect.fit_transform(train_data['article_words'])\n",
    "y_train = train_data['topic'].apply(lambda x: topic_map[x])\n",
    "\n",
    "#for CV use\n",
    "X_full = X_train_vect\n",
    "y_full = y_train\n",
    "\n",
    "X_train_vect, X_test_vect, y_train, y_test = train_test_split(X_train_vect,y_train,test_size=0.2,random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Feature Selection using Mutual Information </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutual_info_select(X_train,y_train,X_test,k):\n",
    "    selector = SelectKBest(mutual_info_classif, k=min(k, X_train.shape[1]))\n",
    "    selector.fit(X_train,y_train)\n",
    "    return selector.transform(X_train),selector.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selects top 10k best features based on mutual_info metric\n",
    "X_train_mic, X_test_mic = mutual_info_select(X_train_vect,y_train,X_test_vect,10000)\n",
    "\n",
    "#selects top 20k best features based on mutual_info metric\n",
    "X_train_mic_2, X_test_mic_2 = mutual_info_select(X_train_vect,y_train,X_test_vect,20000)\n",
    "\n",
    "#selects top 5k best features based on mutual_info metric\n",
    "X_train_mic_3, X_test_mic_3 = mutual_info_select(X_train_vect,y_train,X_test_vect,5000)\n",
    "\n",
    "#selects top 2.5k best features based on mutual_info metric\n",
    "X_train_mic_4, X_test_mic_4 = mutual_info_select(X_train_vect,y_train,X_test_vect,2500)\n",
    "\n",
    "#selects top 1k best features based on mutual_info metric\n",
    "X_train_mic_5, X_test_mic_5 = mutual_info_select(X_train_vect,y_train,X_test_vect,1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Results </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results(name, model,X_train,y_train,X_test,y_test,f1): #f1 is a bool representing whether \n",
    "    pred = model.fit(X_train,y_train).predict(X_test)\n",
    "    train_result = model.score(X_train,y_train)\n",
    "    test_result = accuracy_score(y_test, pred)\n",
    "    b_acc_score = balanced_accuracy_score(y_test,pred)\n",
    "    \n",
    "    print(name)\n",
    "    print(\"The final score for the training database on the MNB classifier is: \", round(train_result, 4))\n",
    "    print(\"The final score for the test database on the MNB classifier is: \", round(test_result, 4))\n",
    "    print(\"The final balance accuracy score for the test set on the MNB classifier is: \", round(b_acc_score, 4), '\\n')\n",
    "    \n",
    "    if(f1):\n",
    "        print(\"\\tPrecision: \", precision_score(y_test,pred,average=None,zero_division=0))\n",
    "        print(\"\\tRecall: \", recall_score(y_test,pred,average=None,zero_division=0))\n",
    "        print(\"\\tF1: \", f1_score(y_test,pred,average=None,zero_division=0),\"\\n\")\n",
    "    \n",
    "    return \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomal Naive Bayes using TFIDF scaling\n",
      "The final score for the training database on the MNB classifier is:  0.6947\n",
      "The final score for the test database on the MNB classifier is:  0.6868\n",
      "The final balance accuracy score for the test set on the MNB classifier is:  0.2215 \n",
      "\n",
      "Multinomal Naive Bayes using counts\n",
      "The final score for the training database on the MNB classifier is:  0.8278\n",
      "The final score for the test database on the MNB classifier is:  0.7463\n",
      "The final balance accuracy score for the test set on the MNB classifier is:  0.5128 \n",
      "\n",
      "Multinomal Naive Bayes using counts and top 10k mutual info features\n",
      "The final score for the training database on the MNB classifier is:  0.778\n",
      "The final score for the test database on the MNB classifier is:  0.7253\n",
      "The final balance accuracy score for the test set on the MNB classifier is:  0.6892 \n",
      "\n",
      "Multinomal Naive Bayes using counts and top 20k mutual info features\n",
      "The final score for the training database on the MNB classifier is:  0.8246\n",
      "The final score for the test database on the MNB classifier is:  0.7421\n",
      "The final balance accuracy score for the test set on the MNB classifier is:  0.5686 \n",
      "\n",
      "Multinomal Naive Bayes using counts and top 5k mutual info features\n",
      "The final score for the training database on the MNB classifier is:  0.7318\n",
      "The final score for the test database on the MNB classifier is:  0.6968\n",
      "The final balance accuracy score for the test set on the MNB classifier is:  0.7499 \n",
      "\n",
      "Multinomal Naive Bayes using counts and top 2.5k mutual info features\n",
      "The final score for the training database on the MNB classifier is:  0.6905\n",
      "The final score for the test database on the MNB classifier is:  0.6674\n",
      "The final balance accuracy score for the test set on the MNB classifier is:  0.7593 \n",
      "\n",
      "\tPrecision:  [0.94444444 0.36697248 0.4        0.5483871  0.25287356 0.62790698\n",
      " 0.61764706 0.94384058 0.61111111 0.40145985 0.34951456]\n",
      "\tRecall:  [0.97356828 0.85106383 0.82051282 0.77272727 0.81481481 0.62790698\n",
      " 0.85714286 0.57315732 0.61111111 0.63218391 0.81818182]\n",
      "\tF1:  [0.95878525 0.51282051 0.53781513 0.64150943 0.38596491 0.62790698\n",
      " 0.71794872 0.71321013 0.61111111 0.49107143 0.48979592] \n",
      "\n",
      "Multinomal Naive Bayes using counts and top 1k mutual info features\n",
      "The final score for the training database on the MNB classifier is:  0.6697\n",
      "The final score for the test database on the MNB classifier is:  0.6568\n",
      "The final balance accuracy score for the test set on the MNB classifier is:  0.7525 \n",
      "\n",
      "\n",
      "\n",
      "Total execution time:  0:00:03.224496\n"
     ]
    }
   ],
   "source": [
    "##Results \n",
    "\n",
    "# Time the total execution.\n",
    "total_time = datetime.now()\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "\n",
    "#1. Implement Multinomial Naive Bayes (MNB) using TFIDF scaling\n",
    "results(\"Multinomal Naive Bayes using TFIDF scaling\",mnb,train_X,train_labels,val_X,val_labels,0)\n",
    "\n",
    "#2. Implement Multinomial Naive Bayes (MNB) using counts\n",
    "results(\"Multinomal Naive Bayes using counts\",mnb,X_train_vect,y_train,X_test_vect,y_test,0)\n",
    "\n",
    "#3. Implement Multinomial Naive Bayes (MNB) using counts and top 10k mutual info features\n",
    "results(\"Multinomal Naive Bayes using counts and top 10k mutual info features\",\n",
    "        mnb,X_train_mic,y_train,X_test_mic,y_test,0)\n",
    "\n",
    "#4. Implement Multinomial Naive Bayes (MNB) using counts and top 20k mutual info features\n",
    "results(\"Multinomal Naive Bayes using counts and top 20k mutual info features\",\n",
    "        mnb,X_train_mic_2,y_train,X_test_mic_2,y_test,0)\n",
    "\n",
    "#5.Implement Multinomial Naive Bayes (MNB) using counts and top 5k mutual info features\n",
    "results(\"Multinomal Naive Bayes using counts and top 5k mutual info features\",\n",
    "        mnb,X_train_mic_3,y_train,X_test_mic_3,y_test,0)\n",
    "\n",
    "#6.Implement Multinomial Naive Bayes (MNB) using counts and top 2.5k mutual info features\n",
    "results(\"Multinomal Naive Bayes using counts and top 2.5k mutual info features\",\n",
    "        mnb,X_train_mic_4,y_train,X_test_mic_4,y_test,1)\n",
    "\n",
    "#7.Implement Multinomial Naive Bayes (MNB) using counts and top 1k mutual info features\n",
    "results(\"Multinomal Naive Bayes using counts and top 1k mutual info features\",\n",
    "        mnb,X_train_mic_5,y_train,X_test_mic_5,y_test,0)\n",
    "\n",
    "\n",
    "print('\\n\\nTotal execution time: ', datetime.now() - total_time)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Score for best NB model (top 2.5k mutual_info features):  0.742106912974923\n"
     ]
    }
   ],
   "source": [
    "#CV Score of Best NB\n",
    "\n",
    "#selects top 2.5k best features based on mutual_info metric\n",
    "X_mic, _ = mutual_info_select(X_full,y_full,X_test_vect,2500)\n",
    "\n",
    "best_score = cross_val_score(mnb,X_mic,y_full,scoring='balanced_accuracy',cv=5)\n",
    "print(\"CV Score for best NB model (top 2.5k mutual_info features): \", np.mean(best_score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
