{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "from Preprocessing import prepare_data\n",
    "from Preprocessing import topics_to_num\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import balanced_accuracy_score \n",
    "from sklearn.metrics import precision_score \n",
    "from sklearn.metrics import recall_score \n",
    "from sklearn.metrics import f1_score \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing.\n",
    "\n",
    "# Get the training data.\n",
    "train_data = pd.read_csv(\"training.csv\")\n",
    "# test_data = pd.read_csv(\"test.csv\")\n",
    "\n",
    "\n",
    "# Pre-process the training data.\n",
    "train_X, val_X, train_labels, val_labels, num_classes, topic_map = prepare_data()\n",
    "\n",
    "# Pre-process for counts\n",
    "vect = CountVectorizer()\n",
    "\n",
    "X_train_vect = vect.fit_transform(train_data['article_words'])\n",
    "y_train = train_data['topic'].apply(lambda x: topic_map[x])\n",
    "\n",
    "X_train_vect, X_test_vect, y_train, y_test = train_test_split(X_train_vect,y_train,test_size=0.2,random_state=42)\n",
    "\n",
    "# X_test_vect = vect.transform(test_data['article_words'])\n",
    "# y_test = test_data['topic'].apply(lambda x: topic_map[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Feature Selection using Mutual Information </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selects top 10k best features based on mutual_info metric\n",
    "selector_1 = SelectKBest(mutual_info_classif, k=min(10000, X_train_vect.shape[1])) \n",
    "selector_1.fit(X_train_vect, y_train)\n",
    "\n",
    "#Transform features\n",
    "X_train_mic = selector_1.transform(X_train_vect)\n",
    "X_test_mic = selector_1.transform(X_test_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selects top 20k best features based on mutual_info metric\n",
    "selector_2 = SelectKBest(mutual_info_classif, k=min(20000, X_train_vect.shape[1])) \n",
    "selector_2.fit(X_train_vect, y_train)\n",
    "\n",
    "#Transform features\n",
    "X_train_mic_2 = selector_2.transform(X_train_vect)\n",
    "X_test_mic_2 = selector_2.transform(X_test_vect)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selects top 5k best features based on mutual_info metric\n",
    "selector_3 = SelectKBest(mutual_info_classif, k=min(5000, X_train_vect.shape[1])) \n",
    "selector_3.fit(X_train_vect, y_train)\n",
    "\n",
    "#Transform features\n",
    "X_train_mic_3 = selector_3.transform(X_train_vect)\n",
    "X_test_mic_3 = selector_3.transform(X_test_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selects top 2.5k best features based on mutual_info metric\n",
    "selector_4 = SelectKBest(mutual_info_classif, k=min(2500, X_train_vect.shape[1])) \n",
    "selector_4.fit(X_train_vect, y_train)\n",
    "\n",
    "#Transform features\n",
    "X_train_mic_4 = selector_4.transform(X_train_vect)\n",
    "X_test_mic_4 = selector_4.transform(X_test_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selects top 1k best features based on mutual_info metric\n",
    "selector_5 = SelectKBest(mutual_info_classif, k=min(1000, X_train_vect.shape[1])) \n",
    "selector_5.fit(X_train_vect, y_train)\n",
    "\n",
    "#Transform features\n",
    "X_train_mic_5 = selector_5.transform(X_train_vect)\n",
    "X_test_mic_5 = selector_5.transform(X_test_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final score for the training database on the MNB classifier is:  0.6922\n",
      "The final score for the test database on the MNB classifier is:  0.6921\n",
      "The final balance accuracy score for the test set on the MNB classifier is:  0.2232 \n",
      "\n",
      "The final score for the training database on the count MNB classifier is:  0.8278\n",
      "The final score for the test database on the count MNB classifier is:  0.7463\n",
      "The final balance accuracy score for the test set on the count MNB classifier is:  0.5128 \n",
      "\n",
      "The final training score on the top 10k mutual info feature selection MNB classifier is:  0.778\n",
      "The final test score on the top 10k mutual info feature selection MNB classifier is:  0.7253\n",
      "The final balance accuracy score on the top 10k mutual info feature selection MNB classifier is:  0.6892 \n",
      "\n",
      "\n",
      "The final training score on the top 20k mutual info feature selection MNB classifier is:  0.8246\n",
      "The final test score on the top 20k mutual info feature selection MNB classifier is:  0.7421\n",
      "The final balance accuracy score on the top 20k mutual info feature selection MNB classifier is:  0.5686 \n",
      "\n",
      "\n",
      "The final training score on the top 5k mutual info feature selection MNB classifier is:  0.7318\n",
      "The final test score on the top 5k mutual info feature selection MNB classifier is:  0.6968\n",
      "The final balance accuracy score on the top 5k mutual info feature selection MNB classifier is:  0.7499 \n",
      "\n",
      "\n",
      "The final training score on the top 2.5k mutual info feature selection MNB classifier is:  0.6905\n",
      "The final test score on the top 2.5k mutual info feature selection MNB classifier is:  0.6674\n",
      "The final balance accuracy score on the top 2.5k mutual info feature selection MNB classifier is:  0.7593 \n",
      "\n",
      "Precision:  [0.62790698 0.4        0.94444444 0.34951456 0.94384058 0.61764706\n",
      " 0.25287356 0.36697248 0.40145985 0.61111111 0.5483871 ]\n",
      "Recall:  [0.62790698 0.82051282 0.97356828 0.81818182 0.57315732 0.85714286\n",
      " 0.81481481 0.85106383 0.63218391 0.61111111 0.77272727]\n",
      "F1:  [0.62790698 0.53781513 0.95878525 0.48979592 0.71321013 0.71794872\n",
      " 0.38596491 0.51282051 0.49107143 0.61111111 0.64150943]\n",
      "\n",
      "The final training score on the top 1k mutual info feature selection MNB classifier is:  0.6697\n",
      "The final test score on the top 1k mutual info feature selection MNB classifier is:  0.6568\n",
      "The final balance accuracy score on the top 1k mutual info feature selection MNB classifier is:  0.7525 \n",
      "\n",
      "\n",
      "\n",
      "Total execution time:  0:00:03.630760\n"
     ]
    }
   ],
   "source": [
    "##Results \n",
    "\n",
    "# Time the total execution.\n",
    "total_time = datetime.now()\n",
    "\n",
    "# Implement Multinomial Naive Bayes (MNB) using TFIDF scaling\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "# Train the MNB classifier.\n",
    "mnb.fit(train_X, train_labels)\n",
    "# Test our MNB results.\n",
    "train_result = mnb.score(train_X, train_labels)\n",
    "print(\"The final score for the training database on the MNB classifier is: \", round(train_result, 4))\n",
    "test_result = mnb.score(val_X, val_labels)\n",
    "pred = mnb.predict(val_X)\n",
    "b_acc_score = balanced_accuracy_score(val_labels,pred)\n",
    "print(\"The final score for the test database on the MNB classifier is: \", round(test_result, 4))\n",
    "print(\"The final balance accuracy score for the test set on the MNB classifier is: \", round(b_acc_score, 4), '\\n')\n",
    "\n",
    "\n",
    "# Implement Multinomial Naive Bayes (MNB) using counts\n",
    "\n",
    "count_mnb = MultinomialNB().fit(X_train_vect,y_train)\n",
    "train_result = count_mnb.score(X_train_vect,y_train)\n",
    "print(\"The final score for the training database on the count MNB classifier is: \", round(train_result, 4))\n",
    "\n",
    "test_result = count_mnb.score(X_test_vect,y_test)\n",
    "print(\"The final score for the test database on the count MNB classifier is: \", round(test_result, 4))\n",
    "\n",
    "pred = count_mnb.predict(X_test_vect)\n",
    "b_acc_score = balanced_accuracy_score(y_test,pred)\n",
    "print(\"The final balance accuracy score for the test set on the count MNB classifier is: \", round(b_acc_score, 4), '\\n')\n",
    "\n",
    "# Implement Multinomial Naive Bayes (MNB) using counts and top 10k mutual info features\n",
    "\n",
    "mic_mnb = MultinomialNB().fit(X_train_mic,y_train)\n",
    "train_result = mic_mnb.score(X_train_mic,y_train)\n",
    "print(\"The final training score on the top 10k mutual info feature selection MNB classifier is: \", round(train_result, 4))\n",
    "\n",
    "test_result = mic_mnb.score(X_test_mic,y_test)\n",
    "print(\"The final test score on the top 10k mutual info feature selection MNB classifier is: \", round(test_result, 4))\n",
    "\n",
    "pred = mic_mnb.predict(X_test_mic)\n",
    "b_acc_score = balanced_accuracy_score(y_test,pred)\n",
    "print(\"The final balance accuracy score on the top 10k mutual info feature selection MNB classifier is: \", round(b_acc_score, 4), '\\n')\n",
    "\n",
    "# Implement Multinomial Naive Bayes (MNB) using counts and top 20k mutual info features\n",
    "\n",
    "mic2_mnb = MultinomialNB().fit(X_train_mic_2,y_train)\n",
    "train_result = mic2_mnb.score(X_train_mic_2,y_train)\n",
    "print(\"\\nThe final training score on the top 20k mutual info feature selection MNB classifier is: \", round(train_result, 4))\n",
    "\n",
    "test_result = mic2_mnb.score(X_test_mic_2,y_test)\n",
    "print(\"The final test score on the top 20k mutual info feature selection MNB classifier is: \", round(test_result, 4))\n",
    "\n",
    "pred = mic2_mnb.predict(X_test_mic_2)\n",
    "b_acc_score = balanced_accuracy_score(y_test,pred)\n",
    "print(\"The final balance accuracy score on the top 20k mutual info feature selection MNB classifier is: \", round(b_acc_score, 4), '\\n')\n",
    "\n",
    "# Implement Multinomial Naive Bayes (MNB) using counts and top 5k mutual info features\n",
    "\n",
    "mic3_mnb = MultinomialNB().fit(X_train_mic_3,y_train)\n",
    "train_result = mic3_mnb.score(X_train_mic_3,y_train)\n",
    "print(\"\\nThe final training score on the top 5k mutual info feature selection MNB classifier is: \", round(train_result, 4))\n",
    "\n",
    "test_result = mic3_mnb.score(X_test_mic_3,y_test)\n",
    "print(\"The final test score on the top 5k mutual info feature selection MNB classifier is: \", round(test_result, 4))\n",
    "\n",
    "pred = mic3_mnb.predict(X_test_mic_3)\n",
    "b_acc_score = balanced_accuracy_score(y_test,pred)\n",
    "print(\"The final balance accuracy score on the top 5k mutual info feature selection MNB classifier is: \", round(b_acc_score, 4), '\\n')\n",
    "\n",
    "# Implement Multinomial Naive Bayes (MNB) using counts and top 2.5k mutual info features\n",
    "\n",
    "mic4_mnb = MultinomialNB().fit(X_train_mic_4,y_train)\n",
    "train_result = mic4_mnb.score(X_train_mic_4,y_train)\n",
    "print(\"\\nThe final training score on the top 2.5k mutual info feature selection MNB classifier is: \", round(train_result, 4))\n",
    "\n",
    "test_result = mic4_mnb.score(X_test_mic_4,y_test)\n",
    "print(\"The final test score on the top 2.5k mutual info feature selection MNB classifier is: \", round(test_result, 4))\n",
    "\n",
    "pred = mic4_mnb.predict(X_test_mic_4)\n",
    "b_acc_score = balanced_accuracy_score(y_test,pred)\n",
    "print(\"The final balance accuracy score on the top 2.5k mutual info feature selection MNB classifier is: \", round(b_acc_score, 4), '\\n')\n",
    "print(\"Precision: \", precision_score(y_test,pred,average=None))\n",
    "print(\"Recall: \", recall_score(y_test,pred,average=None,zero_division=0))\n",
    "print(\"F1: \", f1_score(y_test,pred,average=None))\n",
    "\n",
    "# Implement Multinomial Naive Bayes (MNB) using counts and top 1k mutual info features\n",
    "\n",
    "mic5_mnb = MultinomialNB().fit(X_train_mic_5,y_train)\n",
    "train_result = mic5_mnb.score(X_train_mic_5,y_train)\n",
    "print(\"\\nThe final training score on the top 1k mutual info feature selection MNB classifier is: \", round(train_result, 4))\n",
    "\n",
    "test_result = mic5_mnb.score(X_test_mic_5,y_test)\n",
    "print(\"The final test score on the top 1k mutual info feature selection MNB classifier is: \", round(test_result, 4))\n",
    "\n",
    "pred = mic5_mnb.predict(X_test_mic_5)\n",
    "b_acc_score = balanced_accuracy_score(y_test,pred)\n",
    "print(\"The final balance accuracy score on the top 1k mutual info feature selection MNB classifier is: \", round(b_acc_score, 4), '\\n')\n",
    "\n",
    "print('\\n\\nTotal execution time: ', datetime.now() - total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
