{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "from Preprocessing import prepare_data\n",
    "from Preprocessing import topics_to_num\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing.\n",
    "\n",
    "# Get the training data.\n",
    "train_data = pd.read_csv(\"training.csv\")\n",
    "test_data = pd.read_csv(\"test.csv\")\n",
    "\n",
    "\n",
    "# Pre-process the training data.\n",
    "train_X, val_X, train_labels, val_labels, num_classes, topic_map = prepare_data()\n",
    "\n",
    "# Pre-process for counts\n",
    "vect = CountVectorizer()\n",
    "\n",
    "X_train_vect = vect.fit_transform(train_data['article_words'])\n",
    "y_train = train_data['topic'].apply(lambda x: topic_map[x])\n",
    "\n",
    "X_test_vect = vect.transform(test_data['article_words'])\n",
    "y_test = test_data['topic'].apply(lambda x: topic_map[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Feature Selection using Mutual Information </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectKBest(k=10000, score_func=<function mutual_info_classif at 0x1474315f0>)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#selects top 10k best features based on mutual_info metric\n",
    "selector_1 = SelectKBest(mutual_info_classif, k=min(10000, X_train_vect.shape[1])) \n",
    "selector_1.fit(X_train_vect, y_train)\n",
    "\n",
    "#Transform features\n",
    "X_train_mic = selector_1.transform(X_train_vect)\n",
    "X_test_mic = selector_1.transform(X_test_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selects top 20k best features based on mutual_info metric\n",
    "selector_2 = SelectKBest(mutual_info_classif, k=min(20000, X_train_vect.shape[1])) \n",
    "selector_2.fit(X_train_vect, y_train)\n",
    "\n",
    "#Transform features\n",
    "X_train_mic_2 = selector_2.transform(X_train_vect)\n",
    "X_test_mic_2 = selector_2.transform(X_test_vect)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final score for the training database on the MNB classifier is:  0.6967\n",
      "The final score for the test database on the MNB classifier is:  0.6784 \n",
      "\n",
      "The final score for the training database on the count MNB classifier is:  0.8233\n",
      "The final score for the test database on the count MNB classifier is:  0.728 \n",
      "\n",
      "The final training score on the top 10k mutual info feature selection MNB classifier is:  0.7632\n",
      "The final test score on the top 10k mutual info feature selection MNB classifier is:  0.68\n",
      "\n",
      "The final training score on the top 20k mutual info feature selection MNB classifier is:  0.8131\n",
      "The final test score on the top 20k mutual info feature selection MNB classifier is:  0.72\n",
      "\n",
      "\n",
      "Total execution time:  0:00:00.963211\n"
     ]
    }
   ],
   "source": [
    "##Results \n",
    "\n",
    "# Time the total execution.\n",
    "total_time = datetime.now()\n",
    "\n",
    "# Implement Multinomial Naive Bayes (MNB) using TFIDF scaling\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "# Train the MNB classifier.\n",
    "mnb.fit(train_X, train_labels)\n",
    "# Test our MNB results.\n",
    "train_result = mnb.score(train_X, train_labels)\n",
    "print(\"The final score for the training database on the MNB classifier is: \", round(train_result, 4))\n",
    "test_result = mnb.score(val_X, val_labels)\n",
    "print(\"The final score for the test database on the MNB classifier is: \", round(test_result, 4), '\\n')\n",
    "\n",
    "# Implement Multinomial Naive Bayes (MNB) using counts\n",
    "\n",
    "count_mnb = MultinomialNB().fit(X_train_vect,y_train)\n",
    "train_result = count_mnb.score(X_train_vect,y_train)\n",
    "print(\"The final score for the training database on the count MNB classifier is: \", round(train_result, 4))\n",
    "\n",
    "test_result = count_mnb.score(X_test_vect,y_test)\n",
    "print(\"The final score for the test database on the count MNB classifier is: \", round(test_result, 4), '\\n')\n",
    "\n",
    "# Implement Multinomial Naive Bayes (MNB) using counts and top 10k mutual info features\n",
    "\n",
    "mic_mnb = MultinomialNB().fit(X_train_mic,y_train)\n",
    "train_result = mic_mnb.score(X_train_mic,y_train)\n",
    "print(\"The final training score on the top 10k mutual info feature selection MNB classifier is: \", round(train_result, 4))\n",
    "\n",
    "test_result = mic_mnb.score(X_test_mic,y_test)\n",
    "print(\"The final test score on the top 10k mutual info feature selection MNB classifier is: \", round(test_result, 4))\n",
    "\n",
    "\n",
    "# Implement Multinomial Naive Bayes (MNB) using counts and top 20k mutual info features\n",
    "\n",
    "mic2_mnb = MultinomialNB().fit(X_train_mic_2,y_train)\n",
    "train_result = mic2_mnb.score(X_train_mic_2,y_train)\n",
    "print(\"\\nThe final training score on the top 20k mutual info feature selection MNB classifier is: \", round(train_result, 4))\n",
    "\n",
    "test_result = mic2_mnb.score(X_test_mic_2,y_test)\n",
    "print(\"The final test score on the top 20k mutual info feature selection MNB classifier is: \", round(test_result, 4))\n",
    "\n",
    "\n",
    "print('\\n\\nTotal execution time: ', datetime.now() - total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
